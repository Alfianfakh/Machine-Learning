{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "concisce.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNc5M2D+hBiF4vEMhg4txN5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alfianfakh/Machine-Learning/blob/main/Week9-Multi%20Layer%20Perceptron%20and%20NN/%20concisce.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6JWbkr1Te6a",
        "outputId": "8c2c6296-f5e1-4c3e-d456-aedbf82cd126"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: d2l in /usr/local/lib/python3.7/dist-packages (0.17.5)\n",
            "Requirement already satisfied: pandas==1.2.4 in /usr/local/lib/python3.7/dist-packages (from d2l) (1.2.4)\n",
            "Requirement already satisfied: jupyter==1.0.0 in /usr/local/lib/python3.7/dist-packages (from d2l) (1.0.0)\n",
            "Requirement already satisfied: matplotlib==3.5.1 in /usr/local/lib/python3.7/dist-packages (from d2l) (3.5.1)\n",
            "Requirement already satisfied: requests==2.25.1 in /usr/local/lib/python3.7/dist-packages (from d2l) (2.25.1)\n",
            "Requirement already satisfied: numpy==1.21.5 in /usr/local/lib/python3.7/dist-packages (from d2l) (1.21.5)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.7/dist-packages (from jupyter==1.0.0->d2l) (5.3.1)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from jupyter==1.0.0->d2l) (5.6.1)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from jupyter==1.0.0->d2l) (7.7.0)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from jupyter==1.0.0->d2l) (5.3.1)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from jupyter==1.0.0->d2l) (4.10.1)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.7/dist-packages (from jupyter==1.0.0->d2l) (5.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.5.1->d2l) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.5.1->d2l) (1.4.3)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.5.1->d2l) (4.33.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.5.1->d2l) (0.11.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.5.1->d2l) (3.0.9)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.5.1->d2l) (7.1.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.5.1->d2l) (21.3)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.2.4->d2l) (2022.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests==2.25.1->d2l) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests==2.25.1->d2l) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests==2.25.1->d2l) (2022.6.15)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests==2.25.1->d2l) (3.0.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib==3.5.1->d2l) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7->matplotlib==3.5.1->d2l) (1.15.0)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter==1.0.0->d2l) (5.5.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter==1.0.0->d2l) (5.3.5)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter==1.0.0->d2l) (5.1.1)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter==1.0.0->d2l) (5.1.1)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->d2l) (0.8.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->d2l) (1.0.18)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->d2l) (2.6.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->d2l) (0.7.5)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->d2l) (57.4.0)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->d2l) (4.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->d2l) (4.4.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->jupyter==1.0.0->d2l) (0.2.5)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter==1.0.0->d2l) (1.1.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter==1.0.0->d2l) (3.6.0)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter==1.0.0->d2l) (0.2.0)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter==1.0.0->d2l) (5.4.0)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->d2l) (4.10.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->d2l) (4.3.3)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->d2l) (2.15.3)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->d2l) (21.4.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->d2l) (0.18.1)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->d2l) (5.7.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->d2l) (4.11.4)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema>=2.6->nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->d2l) (3.8.0)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter==1.0.0->d2l) (1.8.0)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter==1.0.0->d2l) (0.13.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter==1.0.0->d2l) (2.11.3)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel->jupyter==1.0.0->d2l) (23.1.0)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook->jupyter==1.0.0->d2l) (0.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook->jupyter==1.0.0->d2l) (2.0.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (0.4)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (0.8.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (1.5.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (0.7.1)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (0.6.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (5.0.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter==1.0.0->d2l) (0.5.1)\n",
            "Requirement already satisfied: qtpy>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter==1.0.0->d2l) (2.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install d2l"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from d2l import tensorflow as d2l"
      ],
      "metadata": {
        "id": "JtX7UFLdUayd"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from d2l import tensorflow as d2l\n",
        "\n",
        "true_w = tf.constant([2, -3.4])\n",
        "true_b = 4.2\n",
        "features, labels = d2l.synthetic_data(true_w, true_b, 1000)"
      ],
      "metadata": {
        "id": "aFyh86FSUdt9"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Reading the Dataset**\n",
        "\n",
        "Rather than rolling our own iterator, we can call upon the existing API in a framework to read data. We pass in features and labels as arguments and specify batch_size when instantiating a data iterator object. Besides, the boolean value is_train indicates whether or not we want the data iterator object to shuffle the data on each epoch (pass through the dataset)."
      ],
      "metadata": {
        "id": "XHLXLu5RUxQc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_array(data_arrays, batch_size, is_train=True):  \n",
        "    \"\"\"Construct a TensorFlow data iterator.\"\"\"\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(data_arrays)\n",
        "    if is_train:\n",
        "        dataset = dataset.shuffle(buffer_size=1000)\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    return dataset\n",
        "\n",
        "batch_size = 10\n",
        "data_iter = load_array((features, labels), batch_size)"
      ],
      "metadata": {
        "id": "zEVSNicHUej4"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(data_iter))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAh3DJwZU7HO",
        "outputId": "3c078463-9852-46dd-ca03-69af0c2cb10a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(10, 2), dtype=float32, numpy=\n",
              " array([[-1.2412069 , -0.90331465],\n",
              "        [ 0.23076609, -0.2844579 ],\n",
              "        [-1.1153182 ,  1.3253522 ],\n",
              "        [-0.9392113 ,  1.8310356 ],\n",
              "        [-0.3381262 ,  0.19587193],\n",
              "        [ 0.45751008, -1.2729384 ],\n",
              "        [ 0.37405133, -0.40867522],\n",
              "        [-0.11861967,  0.63651186],\n",
              "        [-1.6406313 , -0.07380313],\n",
              "        [-0.59609115, -0.3074812 ]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(10, 1), dtype=float32, numpy=\n",
              " array([[ 4.7895536],\n",
              "        [ 5.643553 ],\n",
              "        [-2.5344658],\n",
              "        [-3.9225812],\n",
              "        [ 2.861796 ],\n",
              "        [ 9.441172 ],\n",
              "        [ 6.346199 ],\n",
              "        [ 1.8165407],\n",
              "        [ 1.1686023],\n",
              "        [ 4.051273 ]], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Defining the Model**\n",
        "\n",
        "When we implemented linear regression from scratch in Section 3.2, we defined our model parameters explicitly and coded up the calculations to produce output using basic linear algebra operations. You should know how to do this. But once your models get more complex, and once you have to do this nearly every day, you will be glad for the assistance. The situation is similar to coding up your own blog from scratch. Doing it once or twice is rewarding and instructive, but you would be a lousy web developer if every time you needed a blog you spent a month reinventing the wheel."
      ],
      "metadata": {
        "id": "58yNUDGvVAt_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# `keras` is the high-level API for TensorFlow\n",
        "net = tf.keras.Sequential()\n",
        "net.add(tf.keras.layers.Dense(1))"
      ],
      "metadata": {
        "id": "lIEVo0jeVFcg"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Initializing Model Parameters**\n",
        "\n",
        "Before using net, we need to initialize the model parameters, such as the weights and bias in the linear regression model. Deep learning frameworks often have a predefined way to initialize the parameters. Here we specify that each weight parameter should be randomly sampled from a normal distribution with mean 0 and standard deviation 0.01. The bias parameter will be initialized to zero"
      ],
      "metadata": {
        "id": "_qLEhCo1VIqF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "initializer = tf.initializers.RandomNormal(stddev=0.01)\n",
        "net = tf.keras.Sequential()\n",
        "net.add(tf.keras.layers.Dense(1, kernel_initializer=initializer))"
      ],
      "metadata": {
        "id": "UgRWRNT2VGxG"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Defining the Loss Function**"
      ],
      "metadata": {
        "id": "hPXXr-nJVX6v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xYg-GNmdVX2P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss = tf.keras.losses.MeanSquaredError()"
      ],
      "metadata": {
        "id": "ydoe32hsVWa7"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Defining the Optimization Algorithm**"
      ],
      "metadata": {
        "id": "XZ-cKfs1Veki"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = tf.keras.optimizers.SGD(learning_rate=0.03)"
      ],
      "metadata": {
        "id": "9sMrp33WVTmM"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Training**\n",
        "\n",
        "You might have noticed that expressing our model through high-level APIs of a deep learning framework requires comparatively few lines of code. We did not have to individually allocate parameters, define our loss function, or implement minibatch stochastic gradient descent. Once we start working with much more complex models, advantages of high-level APIs will grow considerably. However, once we have all the basic pieces in place, the training loop itself is strikingly similar to what we did when implementing everything from scratch."
      ],
      "metadata": {
        "id": "hLNAcJ_aVmuK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 3\n",
        "for epoch in range(num_epochs):\n",
        "    for X, y in data_iter:\n",
        "        with tf.GradientTape() as tape:\n",
        "            l = loss(net(X, training=True), y)\n",
        "        grads = tape.gradient(l, net.trainable_variables)\n",
        "        trainer.apply_gradients(zip(grads, net.trainable_variables))\n",
        "    l = loss(net(features), labels)\n",
        "    print(f'epoch {epoch + 1}, loss {l:f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyeo0-_pVmP8",
        "outputId": "dde2ecc0-3a73-47f9-9901-aaaa3d896410"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1, loss 0.000246\n",
            "epoch 2, loss 0.000096\n",
            "epoch 3, loss 0.000096\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w = net.get_weights()[0]\n",
        "print('error in estimating w', true_w - tf.reshape(w, true_w.shape))\n",
        "b = net.get_weights()[1]\n",
        "print('error in estimating b', true_b - b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8aY3riDVTSr",
        "outputId": "f6fc349b-54e7-488b-9e81-bf4ca98248a0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "error in estimating w tf.Tensor([-0.00025702 -0.00066423], shape=(2,), dtype=float32)\n",
            "error in estimating b [0.0001874]\n"
          ]
        }
      ]
    }
  ]
}